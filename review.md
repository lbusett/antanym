## Package Review

*Please check off boxes as applicable, and elaborate in comments below.  Your review is not limited to these topics, as described in the reviewer guide*

- [X] As the reviewer I confirm that there are no conflicts of interest for me to review this work (If you are unsure whether you are in conflict, please speak to your editor _before_ starting your review).

#### Documentation

The package includes all the following forms of documentation:

- [X] **A statement of need** clearly stating problems the software is designed to solve and its target audience in README
- [X] **Installation instructions:** for the development version of package and any non-standard dependencies in README
- [X] **Vignette(s)** demonstrating major functionality that runs successfully locally
- [X] **Function Documentation:** for all exported functions in R help
- [X] **Examples** for all exported functions in R Help that run successfully locally
- [X] **Community guidelines** including contribution guidelines in the README or CONTRIBUTING, and DESCRIPTION with `URL`, `BugReports` and `Maintainer` (which may be autogenerated via `Authors@R`).

>##### For packages co-submitting to JOSS
>
>- [ ] The package has an **obvious research application** according to [JOSS's definition](http://joss.theoj.org/about#submission_requirements)
>
>The package contains a `paper.md` matching [JOSS's requirements](http://joss.theoj.org/about#paper_structure) with:
>
>- [ ] **A short summary** describing the high-level functionality of the software
>- [ ] **Authors:**  A list of authors with their affiliations
>- [ ] **A statement of need** clearly stating problems the software is designed to solve and its target audience.
>- [ ] **References:** with DOIs for all those that have one (e.g. papers, datasets, software).

#### Functionality

- [X] **Installation:** Installation succeeds as documented.
- [X] **Functionality:** Any functional claims of the software been confirmed.
- [X] **Performance:** Any performance claims of the software been confirmed.
- [ ] **Automated tests:** Unit tests cover essential functions of the package
   and a reasonable range of inputs and conditions. All tests pass on the local machine.
   
   Tests are present and appear to cover the main functionalities. However, when running
   `devtools::test()` from RStudio "build panel" many tests fail with a "object 'g' not found"
   error. Running from the console, most tests pass but only if the `g` object 
   was created beforehand with `an_read()`
   
- [ ] **Packaging guidelines**: The package conforms to the rOpenSci packaging guidelines

#### Final approval (post-review)

- [ ] **The author has responded to my review and made changes to my satisfaction. I recommend approving this package.**

Estimated hours spent reviewing: 5

---

### Review Comments

The `antanym` package allows easily accessing to Antarctic geographic place name information, and 
provides  some helper functions useful to filter, "disambiguate" and facilitate plotting
of Antarctic named locations. Although "simple in scope", those helper functions
are well thought and useful to facilitate the use of the dataset. In particular, 
the `an_filter` function allows to easily query the dataset, based both on location and 
on "semantics". The `an_suggest` and `an_thin` functions provide a clever way (IMO)
to facilitate plotting of Antarctic named locations over a map.

The package is generally already in good shape. Documentation is good (though the 
package vignette could be a bit expanded and improved), and inline comments
allow to easily navigate through the code base. Below, I report some suggestions 
for possible improvements I compiled while reviewing the package. Most concern minor
issues and/or suggestions for improvements or corrections on documentation. The only 
"major" suggestion concerns the implementation of the "data caching" mechanism, which could
be maybe improved by using package `rappdirs`.

### Comments on Functions

#### an_read()

- Though I like the solution used by the authors to allow "caching" of the data in a folder
selected by the user (also because the download of the file is quite slow), I think that 
it could be better improved. At the moment, the user has to manually specify the folder where the data will be cached. 
However, it appears that if in another session he wants to use again the cached
 data he will have to remember where exactly he saved it in the first place. 
I think that a better solution could be to use package `rappdirs` so that the data is placed 
automatically in a "standard" folder (e.g. `file.path(user_data_dir(), "antanym")`. 
That way, the user could just use a "flag" argument (e.g., use_cache_dir == TRUE). 
The first time, this would lead to download to a CSV in the "standard" folder. Later
on, the CSV would be automatically found and data loaded from it. 

- Download times are a bit "erratic". Sometimes the data is downloaded quickly, 
other times it can take some minutes. In a couple of cases, I got the 
following error: 

> Error in curl::curl_fetch_memory(url, handle = handle) : 
  Error while processing content unencoding: incorrect data check 

would it be possible to have the user download a "zipped" version of the dataset? 
That would allow reducing the download size from 22 MB to about 3 MB

- You could consider modifying the "do_fetch_data" function to allow automatic retry on failure, 
for a given number of times. Something on the lines: 
```
temp <- httr::RETRY("GET", download_url, httr::config(ssl_verifypeer = 0L),
                                times = 10,
                                pause_base = 0.1,
                                pause_cap = 3,
                                quiet = FALSE)
```


#### an_filter()

-  I'd suggest to allow users to pass the search extent also using an
`sp::bbox` object (This would allow to use, for example, something like: 
`suggested <- an_filter(g, extent = sp::bbox(my_sp_object))`)

- The documentation/examples for the "query" argument could be maybe improved. It is mentioned 
in the documentation that it should be a "regular expression" but I think that 
some more simple examples could help, since many people (included me) often struggle
with regexes. 
For example, something explaining that `query = "West Arm"` performs an "AND" search, while to 
do an "OR" search one should use `query = "West|Arm"`, or explaining how 
to search for a whole word/string) (e.g., `query = "\\bUfs\\b")` - is there an easier way? ).

- It could be worth mentioning that the search (seems to) consider "separated words" as separated 
search terms, so that for example `an_filter(g,  "William Archipelago")` matches "William Scoresby Archipelago", 
which would not happen if using a "standard" regex matching. I think that this is 
a nice behaviour, but it should maybe mentioned in the documentation.

- The search uses by default an ignore_case rule in matching the regex. 
For example, `query = "West"` matches with placename "Sylwester". I think it could be useful
to provide an option to turn on/off the behavior. 

#### an_preferred()

- I do not really get from the documentation how the duplicated features are resolved.
I mean: suppose that one feature has three duplicates, from Poland, Argentina and UK and I 
use origin_country = Canada: what of the three duplicates I would get? Apparently, 
I'd get the first one in alphabetical order (for example, for Booth Island I get Argentina
- did not test it further). Is there a rationale for this behaviour? I feel this should be better documented, and that
the identification of the "single" entry for features for which the "country" selected
by the user does not exist should follow some kind of "standard".  

- Would it make sense to allow the user to search ONLY for features specified by
a given country? Something like: `an_preferred(g, "POLAND", strict  = TRUE)`

- I think it could make sense to allow users to select the "preferred" entry also using the 
"cga_source_gazetter", as happens in `an_filter()`. Is there anything preventing this?
Also, is there any difference between the "country name" and the "cga source"
fields, or there is a 1-1 match? 

_minor_ Also, I'd suggest lengthening a bit the Description in the documentation to detail how 
the selection is based (i.e., by specifying a preferred Country). 

#### an_countries(), an_feature_types(), an_cga_sources(), an_gazetters()

_minor_ The documentation for these functions "points" to the documentation of `an_filter()`
, which however does a different job. I'd propose creating a different Rd for the
three functions. It's "description" could be something on the lines of "find out the possible
values available for fine tuning queries in `an_filter`"

#### an_url()

_minor_ I'd suggest changing the function name to `an_geturl`, but leave the decision
to the authors. 

_minor_ You could maybe consider adding a "piped" example such as:

`aa <- an_filter(g, "Ufs Island")[1, ] %>% 
  an_url(.) %>% 
  browseURL(.)`


#### an_suggest()

I really like this function in association with `an_thin` to allow identify
suitable names for plotting. Some minor comments: 

- As for `an_filter`, I'd suggest to allow users to pass the extent object also using an
`sp::bbox` object (This would allow to use, for example, something like: 
`suggested <- an_suggest(g, map_extent = sp::bbox(my_sp_object), map_dimensions = c(100, 100))`)
 
- The description could be improved. For example, I do not really get how the score
is assigned. The sentence saying that it is "based on how often (and at what map scales) 
they have been named on maps prepared by expert cartographers" is a bit obscure to me. 

- According to documentation, `map_extent` is ignored if `map_scale` is provided. However, 
running `suggested <- an_suggest(g,  map_scale = 10e6)` crashes. I guess that comment
is only valid for `map_dimensions`.

- The documentation states that "gaz" should be a "_data.frame or SpatialPointsDataFrame: 
as returned by an_read_". For completeness, I think however that is should be 
"_as returned by an_read, an_preferred or an_filter_"

#### an_thin()

- The documentation reports that "gaz" should be a "_data.frame or SpatialPointsDataFrame: 
as returned by an_read_"
I think however that is should be **"as returned by an_suggest"**

- Although the user is expected to use the `score_col` argument to 
specify the "scoring" column, no check appears to be done to see if the column
exists. I'd suggest adding an assertion on column names in the code, sending 
a meaningful error message in case the column is not present (this would also 
prevent trying to apply the function on an "un_suggested" antanym dataset).


### Comments on Vignettes

- The vignette duplicates the content of the README. While I think that for the 
readme the content is sufficient, I believe that some additional examples of usage should be 
included in the "full" vignette. I give some suggestions for the authors below. 

- - I'd suggest introducing an additional "section separator" named like "Filtering antanym locations"
where you illustrate in some more detail the "filtering" functionality. I'd start with some  
examples of "queries" based on place_name (could be taken from the examples). After the "feature_id" based query,
I'd start off with some simple queries based on place names and regexes, then introduce the 
`an_preferred` functionality, the `feature_type` functionality and finally the `an_near`
functionality. 

- - The name of the second section could be changed to something like 
"plotting antanym locations". Then start with a "vanilla" case (i.e., not 
using the suggestion feature), and then introducing `an_suggests()`

- - Since you mention that you wish to submit to CRAN, and `rworldmap` is a suggested
package, I think you should probably wrap the r chunks using it in a 
`if(requireNamespace(rworldmap)` construct (the same goes for all examples using it).

- - _minor_ The vignette only illustrates the case of using the package while caching
to tempdir(). For completeness, you could maybe consider showing out first 
the case without cache_dir. 

### Comments on Examples

- In the examples, sometimes a "local" folder is specified (e.g., "c:/temp/gaz").
It would be better to always use `cahe_dir = tempdir()` to facilitate running the 
examples (this would however be solved automatically if implementing the suggestion above
regarding `rappdirs` usage.)

- In the `an_filter` example, I'd suggest adding some code comments explaining what 
the various example do (e.g., "Find locations nearby... etc.")

### Comments on Inline documentation

Inline documentation is good. I'd just suggest however to introduce carriage returns
to shorten long lines in the roxygen sections (I do not think that they will be caught
by lintr/goodpractice). This would improve readability while working on code in
case the "soft wrap" RStudio functionality is off (or the developre does not use RStudio).

### Other Comments

Personally, I think that having at least all "major" functions of a package in separate .R 
files named based on the function allows easier navigation of the code base. However, since 
this is not contemplated in the rOpensci packaging guide, I leave it just as a suggestion. 

That's all. Thanks for sharing this interesting packaging (and thanks to rOpensci for 
asking me to review it - Since this was my first review, I hope 
it fullfills requirements/expectations).
